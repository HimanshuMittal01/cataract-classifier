{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from rich import print\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cataract_classifier.utils import display_dir_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"../input/processed_images/\")\n",
    "\n",
    "display_dir_items(dataset_path / \"train/cataract/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths = [filepath for filepath in (dataset_path / \"train/\").rglob(\"*\") if filepath.is_file()]\n",
    "test_img_paths = [filepath for filepath in (dataset_path / \"test/\").rglob(\"*\") if filepath.is_file()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the first image found for each class\n",
    "DISPLAY_NUM_IMAGES = 40\n",
    "sample_image_paths = random.sample(train_img_paths, k=DISPLAY_NUM_IMAGES)\n",
    "sample_labels = [path.parent.stem for path in sample_image_paths]\n",
    "\n",
    "# Calculate the number of rows and columns\n",
    "grid_size = math.floor(math.sqrt(len(sample_image_paths)))\n",
    "n_rows = grid_size+(1 if grid_size**2 < len(sample_image_paths) else 0)\n",
    "n_cols = grid_size\n",
    "\n",
    "def bordered_image(img, label, border_width=5):\n",
    "    ny, nx, b = img.shape[0], img.shape[1], border_width\n",
    "    framed_img = np.zeros((b+ny+b, b+nx+b, img.shape[2]))\n",
    "    if label.lower() == \"cataract\":\n",
    "        framed_img[:, :, 0] = 255\n",
    "    else:\n",
    "        framed_img[:, :, 1] = 255\n",
    "    framed_img[b:-b, b:-b] = img\n",
    "    framed_img = framed_img.astype(np.uint8)\n",
    "    return framed_img\n",
    "\n",
    "# Create a figure for the grid\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(12,12))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    # If we have an image for this subplot\n",
    "    if i < len(sample_image_paths) and sample_image_paths[i]:\n",
    "        label = sample_labels[i]\n",
    "        img = bordered_image(np.array(Image.open(sample_image_paths[i]).convert('RGB')), label, border_width=2)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(label)\n",
    "\n",
    "    # Remove the axis\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the color of the eyeball is the distinguishing factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax[0].scatter(\n",
    "    x=[Image.open(f).width for f in train_img_paths],\n",
    "    y=[Image.open(f).height for f in train_img_paths],\n",
    "    marker=\"o\",\n",
    "    s=3.0,\n",
    "    alpha=0.5\n",
    ")\n",
    "ax[0].set_xlabel(\"Width\")\n",
    "ax[0].set_ylabel(\"Height\")\n",
    "ax[0].set_title(\"Train Images Aspect Ratio (Width vs Height)\")\n",
    "\n",
    "ax[1].scatter(\n",
    "    x=[Image.open(f).width for f in test_img_paths],\n",
    "    y=[Image.open(f).height for f in test_img_paths],\n",
    "    marker=\"o\",\n",
    "    s=3.0,\n",
    "    alpha=0.5\n",
    ")\n",
    "ax[1].set_xlabel(\"Width\")\n",
    "ax[1].set_ylabel(\"Height\")\n",
    "ax[1].set_title(\"Test Images Aspect Ratio (Width vs Height)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few images have very high resolution. We're going to use mini-batch gradient descent for optimization where these small number of samples won't affect model performance.\n",
    "\n",
    "Data Augmentation will be applied during training through pytorch dataloaders and albumentation transforms.\n",
    "\n",
    "Also note that no image is corrupted as the above scatter plot is created by reading all training images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring available pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "print(timm.list_models(\"*efficientnet*\", pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.models import efficientnet\n",
    "\n",
    "model_cfg = efficientnet.default_cfgs['efficientnet_b0'].default.to_dict()\n",
    "print(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
